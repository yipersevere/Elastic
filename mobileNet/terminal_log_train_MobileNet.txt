yi@yi-ThinkStation-P510:/media/yi/e7036176-287c-4b18-9609-9811b8e33769/ElasticNN/trainModel_withCIFAR/mobileNet$ python pretrain_MobileNet_CIFAR100.py 
/home/yi/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[07.05.2018 21:16:50] Pre-training CIFAR-100 on MobileNet, alpha = 0.75...
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_7_5_128_tf_no_top.h5
10633216/10626956 [==============================] - 4s 0us/step
[07.05.2018 21:16:59] Model summary:
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] Layer (type)                 Output Shape              Param #   
[07.05.2018 21:16:59] =================================================================
[07.05.2018 21:16:59] input_1 (InputLayer)         (None, 128, 128, 3)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv1 (Conv2D)               (None, 64, 64, 24)        648       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv1_bn (BatchNormalization (None, 64, 64, 24)        96        
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv1_relu (Activation)      (None, 64, 64, 24)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 24)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 24)        216       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_1_bn (BatchNormaliza (None, 64, 64, 24)        96        
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_1_relu (Activation)  (None, 64, 64, 24)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_1 (Conv2D)           (None, 64, 64, 48)        1152      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_1_bn (BatchNormaliza (None, 64, 64, 48)        192       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_1_relu (Activation)  (None, 64, 64, 48)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 48)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 48)        432       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_2_bn (BatchNormaliza (None, 32, 32, 48)        192       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_2_relu (Activation)  (None, 32, 32, 48)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_2 (Conv2D)           (None, 32, 32, 96)        4608      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_2_bn (BatchNormaliza (None, 32, 32, 96)        384       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_2_relu (Activation)  (None, 32, 32, 96)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 96)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 96)        864       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_3_bn (BatchNormaliza (None, 32, 32, 96)        384       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_3_relu (Activation)  (None, 32, 32, 96)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_3 (Conv2D)           (None, 32, 32, 96)        9216      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_3_bn (BatchNormaliza (None, 32, 32, 96)        384       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_3_relu (Activation)  (None, 32, 32, 96)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 96)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 96)        864       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_4_bn (BatchNormaliza (None, 16, 16, 96)        384       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_4_relu (Activation)  (None, 16, 16, 96)        0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_4 (Conv2D)           (None, 16, 16, 192)       18432     
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_4_bn (BatchNormaliza (None, 16, 16, 192)       768       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_4_relu (Activation)  (None, 16, 16, 192)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 192)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 192)       1728      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_5_bn (BatchNormaliza (None, 16, 16, 192)       768       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_5_relu (Activation)  (None, 16, 16, 192)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_5 (Conv2D)           (None, 16, 16, 192)       36864     
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_5_bn (BatchNormaliza (None, 16, 16, 192)       768       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_5_relu (Activation)  (None, 16, 16, 192)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 192)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 192)         1728      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_6_bn (BatchNormaliza (None, 8, 8, 192)         768       
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_6_relu (Activation)  (None, 8, 8, 192)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_6 (Conv2D)           (None, 8, 8, 384)         73728     
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_6_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_6_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 384)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 384)         3456      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_7_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_7_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_7 (Conv2D)           (None, 8, 8, 384)         147456    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_7_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_7_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 384)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 384)         3456      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_8_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_8_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_8 (Conv2D)           (None, 8, 8, 384)         147456    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_8_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_8_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 384)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 384)         3456      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_9_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_9_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_9 (Conv2D)           (None, 8, 8, 384)         147456    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_9_bn (BatchNormaliza (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_9_relu (Activation)  (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 384)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 384)         3456      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_10_bn (BatchNormaliz (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_10_relu (Activation) (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_10 (Conv2D)          (None, 8, 8, 384)         147456    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_10_bn (BatchNormaliz (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_10_relu (Activation) (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 384)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 384)         3456      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_11_bn (BatchNormaliz (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_11_relu (Activation) (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_11 (Conv2D)          (None, 8, 8, 384)         147456    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_11_bn (BatchNormaliz (None, 8, 8, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_11_relu (Activation) (None, 8, 8, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 384)       0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 384)         3456      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_12_bn (BatchNormaliz (None, 4, 4, 384)         1536      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_12_relu (Activation) (None, 4, 4, 384)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_12 (Conv2D)          (None, 4, 4, 768)         294912    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_12_bn (BatchNormaliz (None, 4, 4, 768)         3072      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_12_relu (Activation) (None, 4, 4, 768)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 768)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 768)         6912      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_13_bn (BatchNormaliz (None, 4, 4, 768)         3072      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_dw_13_relu (Activation) (None, 4, 4, 768)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_13 (Conv2D)          (None, 4, 4, 768)         589824    
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_13_bn (BatchNormaliz (None, 4, 4, 768)         3072      
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] conv_pw_13_relu (Activation) (None, 4, 4, 768)         0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] flatten_1 (Flatten)          (None, 12288)             0         
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] final_output (Dense)         (None, 100)               1228900   
[07.05.2018 21:16:59] =================================================================
[07.05.2018 21:16:59] Total params: 3,061,876
[07.05.2018 21:16:59] Trainable params: 1,228,900
[07.05.2018 21:16:59] Non-trainable params: 1,832,976
[07.05.2018 21:16:59] _________________________________________________________________
[07.05.2018 21:16:59] 
[07.05.2018 21:16:59] ===================Pretraining the new layer for 100 epochs==================

Epoch 00001: val_loss improved from inf to 3.77008, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00002: val_loss improved from 3.77008 to 3.61299, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00003: val_loss improved from 3.61299 to 3.45790, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00004: val_loss improved from 3.45790 to 3.35024, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00005: val_loss improved from 3.35024 to 3.29691, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00006: val_loss improved from 3.29691 to 3.29142, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00007: val_loss did not improve from 3.29142

Epoch 00008: val_loss did not improve from 3.29142

Epoch 00009: val_loss did not improve from 3.29142

Epoch 00010: val_loss improved from 3.29142 to 3.20626, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model.best.hdf5

Epoch 00011: val_loss did not improve from 3.20626

Epoch 00012: val_loss did not improve from 3.20626

Epoch 00013: val_loss did not improve from 3.20626

Epoch 00014: val_loss did not improve from 3.20626

Epoch 00015: val_loss did not improve from 3.20626

Epoch 00016: val_loss did not improve from 3.20626

Epoch 00017: val_loss did not improve from 3.20626

Epoch 00018: val_loss did not improve from 3.20626

Epoch 00019: val_loss did not improve from 3.20626

Epoch 00020: val_loss did not improve from 3.20626

Epoch 00021: val_loss did not improve from 3.20626

Epoch 00022: val_loss did not improve from 3.20626

Epoch 00023: val_loss did not improve from 3.20626

Epoch 00024: val_loss did not improve from 3.20626

Epoch 00025: val_loss did not improve from 3.20626
previous layers are not trainable, Test accuracy: 27.5300%
[07.05.2018 21:26:47] ====================Pretraining all layers, with including all previours frozened layers====================

Epoch 00001: val_loss improved from inf to 1.56892, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00002: val_loss improved from 1.56892 to 1.30675, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00003: val_loss improved from 1.30675 to 1.29711, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00004: val_loss improved from 1.29711 to 1.27187, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00005: val_loss improved from 1.27187 to 1.26909, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00006: val_loss improved from 1.26909 to 1.24688, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00007: val_loss did not improve from 1.24688

Epoch 00008: val_loss did not improve from 1.24688

Epoch 00009: val_loss did not improve from 1.24688

Epoch 00010: val_loss did not improve from 1.24688

Epoch 00011: val_loss did not improve from 1.24688

Epoch 00012: val_loss did not improve from 1.24688

Epoch 00013: val_loss did not improve from 1.24688

Epoch 00014: val_loss improved from 1.24688 to 1.24556, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00015: val_loss improved from 1.24556 to 1.24542, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00016: val_loss improved from 1.24542 to 1.24304, saving model to ./Pretrained_CIFAR_MobileNet/AGE/hl_MOBILE_0.75__2018-05-07-21-16-23model2.best.hdf5

Epoch 00017: val_loss did not improve from 1.24304

Epoch 00018: val_loss did not improve from 1.24304

Epoch 00019: val_loss did not improve from 1.24304

Epoch 00020: val_loss did not improve from 1.24304

Epoch 00021: val_loss did not improve from 1.24304

Epoch 00022: val_loss did not improve from 1.24304

Epoch 00023: val_loss did not improve from 1.24304

Epoch 00024: val_loss did not improve from 1.24304

Epoch 00025: val_loss did not improve from 1.24304

Epoch 00026: val_loss did not improve from 1.24304

Epoch 00027: val_loss did not improve from 1.24304

Epoch 00028: val_loss did not improve from 1.24304

Epoch 00029: val_loss did not improve from 1.24304

Epoch 00030: val_loss did not improve from 1.24304

Epoch 00031: val_loss did not improve from 1.24304
program elapse:  3342.6974053382874
all layers are trainable, Test accuracy: 73.0600%

